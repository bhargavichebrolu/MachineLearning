# TOPIC 1 — DATA SOURCES (INDUSTRY-GRADE NOTES)

These notes cover **all segments**, including explanations of:
- Data sources
- Structured / Semi-structured / Unstructured data
- Backend logs
- Clickstream events
- Kafka
- Batch vs Streaming  
along with the doubts discussed.

---

## SEGMENT 1 — WHAT IS A DATA SOURCE (FOUNDATION)

### What a Data Source Is
* A **data source** is the **system that produces data**, not the file itself.
* A CSV, JSON, or database table is a **dataset**, not a data source.

### Key Properties of a Data Source
* Origin — who or what generates the data
* Mechanism — how data is generated
* Frequency — how often data is produced
* Schema behavior — how stable the structure is
* Trust level — how reliable the data is

### Dataset vs Data Source
* **Data Source**: Producer of data (application, sensor, service)
* **Dataset**: Snapshot extracted from a data source

### Raw vs Derived Data
* **Raw data**
  * Directly from the source
  * Messy
  * Minimal processing
* **Derived data**
  * Aggregated or transformed
  * Built from raw data
  * Used for modeling

### First-party vs Third-party Data
* **First-party**
  * Collected by your own system
  * High trust
* **Third-party**
  * Collected by others (e.g., Kaggle, public datasets)
  * Lower trust
  * Must acknowledge limitations

---

## SEGMENT 2 — STRUCTURED DATA (DEEP DIVE)

### What Structured Data Means
* Data with a **fixed schema**
* Schema is **enforced at write time**
* Columns, data types, and constraints are predefined

### Common Structured Data Sources
* Relational databases (MySQL, PostgreSQL)
* CSV / TSV files
* Data warehouses

### Schema Components
* Column names
* Data types
* Nullability
* Relationships (primary keys, foreign keys)

### Common Problems in Structured Data
* Missing values
* Duplicate records
* Wrong data types
* Schema evolution (new / removed columns)

### CSV vs TSV
* **CSV** — Comma-separated values
  * Common
  * Breaks easily when text contains commas
* **TSV** — Tab-separated values
  * Safer for text-heavy data
  * Less parsing ambiguity

---

## SEGMENT 3 — SEMI-STRUCTURED DATA (JSON, LOGS)

### What Semi-Structured Data Is
* Data **has structure**
* Structure is **not enforced**
* Schema is applied at read time (schema-on-read)

### Common Sources
* Application logs
* Clickstream events
* API responses
* Event systems

### JSON Characteristics
* Nested objects
* Optional keys
* Arrays
* Inconsistent structure across records

### Common Problems
* Missing keys
* Variable nesting
* Corrupted records
* Late detection of schema issues

### Schema-on-Read
* No validation when data is written
* Errors appear later in pipelines
* High risk for ML systems

---

## BACKEND LOGS (DETAILED EXPLANATION)

### What Backend Logs Are
* Records written by backend services to describe **system behavior**
* Used by developers, testers, SREs, and monitoring systems

### What Backend Logs Are NOT
* Not random print statements
* Not meant for end users

### What Backend Logs Contain
* Timestamp
* Log level (INFO, ERROR, WARN)
* Service name
* Event or message
* Metadata (user_id, error_code, latency)

### Purpose of Backend Logs
* Debugging
* Monitoring
* Auditing
* Security analysis
* ML and anomaly detection

### Key Insight
* Logs show **what happened**, not magically why something didn’t happen
* Engineers infer causes from log evidence

---

## CLICKSTREAM EVENTS

### What Clickstream Events Are
* Records of **user interactions** with a system
* Generated by frontend applications

### Examples
* Page views
* Button clicks
* Add to cart
* Purchases

### Properties
* High volume
* Semi-structured (usually JSON)
* Fields vary by event type

### ML Use Cases
* Recommendation systems
* Churn prediction
* User behavior modeling
* Funnel analysis

### Important Distinction
* Backend logs → system behavior
* Clickstream events → user behavior

---

## KAFKA (FROM ZERO)

### What Kafka Is
* Kafka is **not data**
* Kafka is **not a database**
* Kafka is a **transport system for events**

### Simple Definition
* Kafka collects events and delivers them to whoever needs them, reliably and in order.

### Kafka Mental Model
* Kafka is like a **post office** or **conveyor belt**
* Producers send events to Kafka
* Consumers read events from Kafka

### What an Event Is
* A message describing something that happened
* Example:
  * User clicked
  * Payment failed
  * Sensor reading

### Producers
* Backend services
* Frontend trackers
* Sensors
* APIs

### Consumers
* ML pipelines
* Databases
* Monitoring systems
* Alerting systems

### What Kafka Does
* Stores events temporarily
* Preserves order
* Scales to very high volume

### What Kafka Does NOT Do
* No data cleaning
* No validation
* No understanding of meaning
* No analytics

---

## SEGMENT 5 — BATCH vs STREAMING (TIME & VELOCITY)

### Core Idea
* Difference is **WHEN data is processed**
* Not about tools or file formats

### Batch Processing
* Data is collected
* System waits
* Processes data later in bulk

**Characteristics**
* High latency
* Easier debugging
* Easier reprocessing

**Examples**
* End-of-day transaction CSV
* Nightly model training
* Weekly reports

### Streaming Processing
* Data is processed immediately as it arrives

**Characteristics**
* Low latency
* Harder debugging
* Ordering and duplication issues

**Examples**
* Fraud detection during payment
* Live recommendations
* Real-time alerts

### Key Rule
* Batch = wait first, then process
* Streaming = process immediately

### Kafka and Batch/Streaming
* Kafka does not decide batch or streaming
* Kafka can support both
  * Batch: read events later
  * Streaming: read events immediately

---

## ONE-LINE INTERVIEW TAKEAWAYS

* A data source is the system that produces data, not the file.
* Structured data enforces schema at write time.
* Semi-structured data has schema-on-read.
* Backend logs describe system behavior.
* Clickstream events describe user behavior.
* Kafka is an event transport system.
* Batch systems prioritize correctness.
* Streaming systems prioritize timeliness.

  # HOW TO IDENTIFY DATA TYPE FROM A DATA SOURCE (STRUCTURED vs SEMI-STRUCTURED vs UNSTRUCTURED)

This section explains **HOW we know** what kind of data a data source provides  
**based on the origin of the data**, not guesses.

---

## CORE IDEA (VERY IMPORTANT)

> **The type of data is determined by how the DATA PRODUCER enforces structure,  
> not by how the data looks at first glance.**

Always think about the **source system**, not the file.

---

## STEP 1 — ASK THESE 4 QUESTIONS (MENTAL CHECKLIST)

When you see any data source, ask:

### 1. Is the schema enforced when data is written?
* Yes → Structured
* No → Semi-structured or Unstructured

### 2. Do all records have the same fields?
* Yes → Structured
* No → Semi-structured

### 3. Is the main content human-generated (text, image, audio, video)?
* Yes → Unstructured

### 4. Can this data naturally fit into rows and columns?
* Yes → Structured
* Partially → Semi-structured
* No → Unstructured

This checklist alone solves 80% of confusion.

---

## STEP 2 — IDENTIFY BY DATA SOURCE ORIGIN (INDUSTRY STANDARD)

---

## RELATIONAL DATABASES

### Examples
* MySQL
* PostgreSQL
* Oracle
* SQL Server

### How we know the data type
* Schema is defined in advance
* Columns and data types are enforced
* Invalid data is rejected

### Conclusion
* **Data type: STRUCTURED**

> If the database rejects bad data, the data is structured.

---

## FLAT FILE EXPORTS (CSV / TSV)

### Examples
* Daily reports
* Vendor data dumps
* Historical snapshots

### How we know the data type
* Columns are fixed
* Each row follows the same structure
* Types are assumed per column

### Conclusion
* **Data type: STRUCTURED**

Even though it’s a file, structure is assumed.

---

## APPLICATION LOGS (BACKEND LOGS)

### Examples
* Error logs
* API request logs
* Service logs

### How we know the data type
* Usually JSON or key-value
* Fields may appear or disappear
* No strict validation at write time

### Conclusion
* **Data type: SEMI-STRUCTURED**

> Structure exists, but nothing enforces it.

---

## CLICKSTREAM EVENTS

### Examples
* Page views
* Button clicks
* Add to cart
* Purchases

### How we know the data type
* Event-specific fields
* Different events have different keys
* Generated in real time
* Often JSON

### Conclusion
* **Data type: SEMI-STRUCTURED**

---

## APIs (MOST COMMON CONFUSION)

### Examples
* REST APIs
* External service responses

### How we know the data type
* Usually JSON
* Optional fields
* Version changes over time
* Schema not strictly enforced

### Conclusion
* **Data type: SEMI-STRUCTURED**

Unless explicitly validated (rare).

---

## DATA LAKES (S3, HDFS, ADLS)

### Important clarification
* Storage system does **NOT** define data type
* File format inside storage defines it

### How we decide
| File Type | Data Type |
|---------|----------|
| CSV / TSV | Structured |
| Parquet / ORC | Structured |
| JSON | Semi-structured |
| TXT | Unstructured |
| Images | Unstructured |
| Audio | Unstructured |

---

## HUMAN-GENERATED CONTENT

### Examples
* Reviews
* Emails
* Chat messages
* Images
* Audio recordings
* Videos

### How we know the data type
* No fixed schema
* Meaning is contextual
* Needs interpretation

### Conclusion
* **Data type: UNSTRUCTURED**

Metadata may be structured, but content is not.

---

## EDGE CASES (INTERVIEW IMPORTANT)

---

### JSON WITH FIXED FIELDS

* Still **SEMI-STRUCTURED**
* Because schema is not enforced
* Can break anytime

---

### TEXT WITH METADATA

Example:
* Review text + rating

Classification:
* Text → Unstructured
* Rating → Structured

This is called **HYBRID DATA**.

---

### PARQUET FILES

* Often assumed structured
* Correct thinking:

> Parquet stores structured columns,  
> but data quality depends on upstream source.

---

## ONE-SENTENCE RULE (MEMORISE)

> **Data type is decided by how strictly the PRODUCER enforces schema,  
> not by how clean the data looks.**

---

## HOW TO ANSWER IN INTERVIEWS

### Question
> How do you know what type of data a source provides?

### Strong Answer
> I look at schema enforcement, consistency across records, and the system producing the data.

---

## FINAL QUICK SUMMARY

* Databases → Structured
* CSV / TSV → Structured
* Logs → Semi-structured
* Clickstream → Semi-structured
* APIs → Semi-structured
* Text / Images / Audio → Unstructured
* Storage system does not define data type

